{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from job_shop_lib.dispatching.feature_observers import (\n",
    "    FeatureObserverType,\n",
    ")\n",
    "from job_shop_lib.graphs import build_resource_task_graph\n",
    "from job_shop_lib.reinforcement_learning import (\n",
    "    SingleJobShopGraphEnv,\n",
    "    ResourceTaskGraphObservation,\n",
    "    get_optimal_actions,\n",
    ")\n",
    "from job_shop_lib.dispatching import OptimalOperationsObserver\n",
    "from job_shop_lib import Schedule\n",
    "from gnn_scheduler.utils import get_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = get_data_path()\n",
    "schedules_json = json.load(open(DATA_PATH / \"small_random_instances_0.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(schedules_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_observers_types = [\n",
    "    FeatureObserverType.DURATION,\n",
    "    FeatureObserverType.EARLIEST_START_TIME,\n",
    "    FeatureObserverType.IS_SCHEDULED,\n",
    "    FeatureObserverType.POSITION_IN_JOB,\n",
    "    FeatureObserverType.REMAINING_OPERATIONS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPERATION_FEATURES_TO_NORMALIZE = [\n",
    "    0,  # Duration\n",
    "    1,  # EarliestStartTime\n",
    "    4,  # PositionInJob\n",
    "    5,  # Job duration\n",
    "    6,  # Job earliest start time\n",
    "    9,  # Job remaining operations\n",
    "]\n",
    "MACHINE_FEATURES_TO_NORMALIZE = [\n",
    "    0,  # Duration\n",
    "    1,  # EarliestStartTime\n",
    "    4,  # RemainingOperations\n",
    "]\n",
    "\n",
    "features_to_normalize = {\n",
    "    \"operation\": OPERATION_FEATURES_TO_NORMALIZE,\n",
    "    \"machine\": MACHINE_FEATURES_TO_NORMALIZE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_features(\n",
    "    node_features_dict: dict[str, np.ndarray],\n",
    "    indices_to_normalize: dict[str, list[int]] | None = None,\n",
    "):\n",
    "    if indices_to_normalize is None:\n",
    "        indices_to_normalize = {\n",
    "            \"operation\": np.arange(8),\n",
    "            \"machine\": np.arange(4),\n",
    "        }\n",
    "    for key, indices in indices_to_normalize.items():\n",
    "        # Divide by the maximum value checking for division by zero\n",
    "        max_values = np.max(node_features_dict[key], axis=0)\n",
    "        max_values[max_values == 0] = 1\n",
    "        node_features_dict[key][:, indices] /= max_values[indices]\n",
    "\n",
    "    return node_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for schedule_dict in schedules_json:\n",
    "    observations = []\n",
    "    action_probabilities_sequence = []\n",
    "    schedule = Schedule.from_dict(**schedule_dict)\n",
    "    graph = build_resource_task_graph(schedule.instance)\n",
    "    env = SingleJobShopGraphEnv(\n",
    "        graph, feature_observer_configs=features_observers_types\n",
    "    )\n",
    "    env = ResourceTaskGraphObservation(env)\n",
    "    optimal_ops_observer = OptimalOperationsObserver(\n",
    "        env.unwrapped.dispatcher, schedule\n",
    "    )\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action_probs = get_optimal_actions(\n",
    "            optimal_ops_observer, info[\"available_operations_with_ids\"]\n",
    "        )\n",
    "        if len(action_probs) > 1:\n",
    "            obs[\"node_features_dict\"] = _normalize_features(\n",
    "                obs[\"node_features_dict\"]\n",
    "            )\n",
    "            observations.append(obs)\n",
    "            action_probabilities_sequence.append(action_probs)\n",
    "        _, machine_id, job_id = max(action_probs, key=action_probs.get)\n",
    "        obs, reward, done, _, info = env.step((job_id, machine_id))\n",
    "    makespan = env.unwrapped.dispatcher.schedule.makespan()\n",
    "    assert makespan == schedule.makespan()\n",
    "    dataset[schedule.instance.name] = (\n",
    "        observations,\n",
    "        action_probabilities_sequence,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_names': defaultdict(list,\n",
       "             {<FeatureType.OPERATIONS: 'operations'>: ['Duration',\n",
       "               'EarliestStartTime',\n",
       "               'IsScheduled',\n",
       "               'PositionInJob'],\n",
       "              <FeatureType.MACHINES: 'machines'>: ['Duration',\n",
       "               'EarliestStartTime',\n",
       "               'IsScheduled',\n",
       "               'RemainingOperations'],\n",
       "              <FeatureType.JOBS: 'jobs'>: ['Duration',\n",
       "               'EarliestStartTime',\n",
       "               'IsScheduled',\n",
       "               'RemainingOperations']}),\n",
       " 'available_operations_with_ids': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, action_probabilities_sequence = dataset[schedule.instance.name]\n",
    "assert len(observations) == len(action_probabilities_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hetero_dataset = []\n",
    "for obs, action_probs in zip(observations, action_probabilities_sequence):\n",
    "    hetero_data = HeteroData()\n",
    "    for key, value in obs.items():\n",
    "        for subkey, subvalue in value.items():\n",
    "            if key == \"node_features_dict\":\n",
    "                hetero_data[subkey].x = torch.from_numpy(subvalue)\n",
    "            elif key == \"edge_index_dict\":\n",
    "                hetero_data[subkey].edge_index = torch.from_numpy(subvalue)\n",
    "    hetero_data[\"y\"] = torch.tensor(list(action_probs.values()))\n",
    "    hetero_data[\"valid_pairs\"] = torch.tensor(list(action_probs.keys()))\n",
    "    hetero_dataset.append(hetero_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('operation',\n",
       "  'to',\n",
       "  'operation'): tensor([[ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,  4,  4,\n",
       "           4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  8,\n",
       "           9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13,\n",
       "          13, 13, 14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17,\n",
       "          18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
       "          22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26,\n",
       "          27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 29, 29],\n",
       "         [ 1,  2,  3,  4,  0,  2,  3,  4,  0,  1,  3,  4,  0,  1,  2,  4,  0,  1,\n",
       "           2,  3,  6,  7,  8,  9,  5,  7,  8,  9,  5,  6,  8,  9,  5,  6,  7,  9,\n",
       "           5,  6,  7,  8, 11, 12, 13, 14, 10, 12, 13, 14, 10, 11, 13, 14, 10, 11,\n",
       "          12, 14, 10, 11, 12, 13, 16, 17, 18, 19, 15, 17, 18, 19, 15, 16, 18, 19,\n",
       "          15, 16, 17, 19, 15, 16, 17, 18, 21, 22, 23, 24, 20, 22, 23, 24, 20, 21,\n",
       "          23, 24, 20, 21, 22, 24, 20, 21, 22, 23, 26, 27, 28, 29, 25, 27, 28, 29,\n",
       "          25, 26, 28, 29, 25, 26, 27, 29, 25, 26, 27, 28]]),\n",
       " ('operation',\n",
       "  'to',\n",
       "  'machine'): tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "          18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "         [ 2,  4,  1,  3,  0,  1,  2,  0,  4,  3,  0,  1,  3,  2,  4,  4,  1,  2,\n",
       "           3,  0,  3,  0,  2,  1,  4,  0,  2,  1,  4,  3]]),\n",
       " ('machine',\n",
       "  'to',\n",
       "  'operation'): tensor([[ 0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,\n",
       "           3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4],\n",
       "         [ 4,  7, 10, 19, 21, 25,  2,  5, 11, 16, 23, 27,  0,  6, 13, 17, 22, 26,\n",
       "           3,  9, 12, 18, 20, 29,  1,  8, 14, 15, 24, 28]]),\n",
       " ('machine',\n",
       "  'to',\n",
       "  'machine'): tensor([[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
       "         [1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_dataset[0].edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn_scheduler.model import ResidualSchedulingGNN, HeteroMetadata\n",
    "\n",
    "metadata = HeteroMetadata(node_types=[\"operation\", \"machine\"])\n",
    "\n",
    "\n",
    "model = ResidualSchedulingGNN(\n",
    "    metadata=metadata, in_channels_dict={\"operation\": 8, \"machine\": 4}\n",
    ")\n",
    "\n",
    "a = model(hetero_dataset[0].x_dict, hetero_dataset[0].edge_index_dict, hetero_dataset[0].valid_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  y=[6],\n",
       "  valid_pairs=[6, 3],\n",
       "  operation={ x=[30, 8] },\n",
       "  machine={ x=[5, 4] },\n",
       "  (operation, to, operation)={ edge_index=[2, 120] },\n",
       "  (operation, to, machine)={ edge_index=[2, 30] },\n",
       "  (machine, to, operation)={ edge_index=[2, 30] },\n",
       "  (machine, to, machine)={ edge_index=[2, 20] }\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0851],\n",
       "        [-0.1582],\n",
       "        [-0.0196],\n",
       "        [-0.3940],\n",
       "        [ 0.0272],\n",
       "        [-0.2747],\n",
       "        [ 0.0851],\n",
       "        [-0.1582],\n",
       "        [-0.0196],\n",
       "        [-0.3940],\n",
       "        [ 0.0272],\n",
       "        [-0.2747]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, a], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
